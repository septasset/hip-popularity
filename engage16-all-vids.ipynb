{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on engage16_views notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os, bz2, json, time, tqdm, csv\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"activism\",\"autos\",\"comedy\",\"education\",\"entertainment\", \\\n",
    "              \"film\",\"gaming\",\"howto\",\"movies\",\"music\",\\\n",
    "              \"news\",\"people\",\"pets\",\"science\",\"shows\",\\\n",
    "              \"sports\",\"trailers\",\"travel\"]\n",
    "\n",
    "categories_eligible = [\"autos\",\"comedy\",\"education\",\"entertainment\", \\\n",
    "                       \"film\",\"gaming\",\"howto\",\"music\",\\\n",
    "                       \"news\",\"people\",\"science\",\"sports\",\\\n",
    "                       \"travel\"]\n",
    "\n",
    "dataset_base = \"G:/MLCV dataset/engagement'16/tweeted_videos\"\n",
    "eval_days = [90, 135, 180, 225, 270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_vids(dataset_json):   \n",
    "    vids_set = set()\n",
    "    vids = []\n",
    "\n",
    "    category_id = None\n",
    "    for line in tqdm.tqdm(dataset_json):\n",
    "        record = json.loads(line)\n",
    "        try:\n",
    "            category_id = int(record['snippet']['categoryId'])\n",
    "            day = [int(x) for x in record['insights']['days'].split(\",\")]\n",
    "            \"\"\"!!!\"\"\"\n",
    "#             if len(day) < eval_days[-1]: continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if record['id'] in vids_set:\n",
    "            continue\n",
    "        vids_set.add(record['id'])\n",
    "        vids.append(record['id'])\n",
    "    print(\"dataset size:\", \"{}\".format(len(vids)))\n",
    "    \n",
    "    return vids, category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: autos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 84796/84796 [00:05<00:00, 15859.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 84796\n",
      "Working on: comedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 138068/138068 [00:07<00:00, 17844.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 138068\n",
      "Working on: education\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 182849/182849 [00:10<00:00, 17071.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 182849\n",
      "Working on: entertainment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 775941/775941 [00:43<00:00, 17660.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 775941\n",
      "Working on: film\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 194891/194891 [00:10<00:00, 17768.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 194891\n",
      "Working on: gaming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1079434/1079434 [01:03<00:00, 17068.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 1079434\n",
      "Working on: howto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 192931/192931 [00:12<00:00, 15244.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 192931\n",
      "Working on: music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 449314/449314 [00:27<00:00, 16530.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 449314\n",
      "Working on: news\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 459728/459728 [00:20<00:00, 21925.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 459728\n",
      "Working on: people\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1265805/1265805 [01:06<00:00, 18896.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 1265805\n",
      "Working on: science\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 110635/110635 [00:06<00:00, 15843.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 110635\n",
      "Working on: sports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 243650/243650 [00:12<00:00, 19805.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 243650\n",
      "Working on: travel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 65155/65155 [00:03<00:00, 17811.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 65155\n"
     ]
    }
   ],
   "source": [
    "for test_category in categories_eligible[:]:\n",
    "    print(\"Working on:\", test_category)\n",
    "    with open(os.path.join(dataset_base, test_category+\".json\"), \"r\") as f:\n",
    "        dataset_json = f.readlines()\n",
    "    vids, category_id = get_all_vids(dataset_json)    \n",
    "    out_file = \"./data/engage16/vids_{}({}).csv\".format(test_category, category_id)\n",
    "\n",
    "    with open(out_file, 'w', encoding='utf-8') as f:\n",
    "        # create the csv writer\n",
    "        writer = csv.writer(f)\n",
    "        # write a row to the csv file\n",
    "        writer.writerow(vids[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_vids_filter(dataset_json):   \n",
    "    vids_set = set()\n",
    "    vids = []\n",
    "\n",
    "    category_id = None\n",
    "    for line in tqdm.tqdm(dataset_json):\n",
    "        record = json.loads(line)\n",
    "        try:\n",
    "            category_id = int(record['snippet']['categoryId'])\n",
    "            day = [int(x) for x in record['insights']['days'].split(\",\")]\n",
    "            \"\"\"!!!\"\"\"\n",
    "            if len(day) < eval_days[-1]: continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if record['id'] in vids_set:\n",
    "            continue\n",
    "        vids_set.add(record['id'])\n",
    "        vids.append(record['id'])\n",
    "    print(\"dataset size:\", \"{}\".format(len(vids)))\n",
    "    \n",
    "    return vids, category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: autos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 84796/84796 [00:05<00:00, 15419.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 25712\n",
      "Working on: comedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 138068/138068 [00:07<00:00, 17717.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 31741\n",
      "Working on: education\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 182849/182849 [00:10<00:00, 16781.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 41191\n",
      "Working on: entertainment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 775941/775941 [00:45<00:00, 17135.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 180128\n",
      "Working on: film\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 194891/194891 [00:11<00:00, 17692.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 43101\n",
      "Working on: gaming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1079434/1079434 [01:00<00:00, 17836.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 222236\n",
      "Working on: howto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 192931/192931 [00:13<00:00, 14447.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 61027\n",
      "Working on: music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 449314/449314 [00:29<00:00, 15268.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 118094\n",
      "Working on: news\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 459728/459728 [00:20<00:00, 22018.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 38249\n",
      "Working on: people\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1265805/1265805 [01:10<00:00, 17889.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 222658\n",
      "Working on: science\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 110635/110635 [00:07<00:00, 14305.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 32278\n",
      "Working on: sports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 243650/243650 [00:12<00:00, 19197.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 39649\n",
      "Working on: travel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 65155/65155 [00:03<00:00, 17073.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 13112\n"
     ]
    }
   ],
   "source": [
    "for test_category in categories_eligible[:]:\n",
    "    print(\"Working on:\", test_category)\n",
    "    with open(os.path.join(dataset_base, test_category+\".json\"), \"r\") as f:\n",
    "        dataset_json = f.readlines()\n",
    "    vids, category_id = get_all_vids_filter(dataset_json)\n",
    "    vids.insert(0, test_category)\n",
    "    out_file = \"./data/engage16/filtered/vids_filter(all).csv\"\n",
    "\n",
    "    with open(out_file, 'a', encoding='utf-8') as f:\n",
    "        # create the csv writer\n",
    "        writer = csv.writer(f)\n",
    "        # write a row to the csv file\n",
    "        writer.writerow(vids[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hip-long",
   "language": "python",
   "name": "hip-long"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
